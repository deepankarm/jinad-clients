/**
 * JinaD (Daemon)
 * REST interface for managing distributed Jina
 *
 * The version of the OpenAPI document: 0.9.32
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { RequestFile } from './models';

export class PeaModel {
    /**
    *  The name of this object.  This will be used in the following places: - how you refer to this object in Python/YAML/CLI - log message - ...  When not given, then the default naming strategy will apply.                     
    */
    'name'?: string;
    /**
    * The YAML config of the logger used in this object.
    */
    'logConfig'?: string;
    /**
    * If set, then exception stack information to be added to the logging message, useful in debugging
    */
    'hideExcInfo'?: boolean;
    /**
    * The port for controlling the runtime, default a random port between [49152, 65535]
    */
    'portCtrl'?: number;
    /**
    * If set, use ipc protocol for control socket
    */
    'ctrlWithIpc'?: boolean;
    /**
    * The timeout in milliseconds of the control request, -1 for waiting forever
    */
    'timeoutCtrl'?: number;
    /**
    * The SSH server through which the tunnel will be created, can actually be a fully specified `user@server:port` ssh url.
    */
    'sshServer'?: string;
    /**
    * This specifies a key to be used in ssh login, default None. regular default ssh keys will be used without specifying this argument.
    */
    'sshKeyfile'?: string;
    /**
    * The ssh password to the ssh server.
    */
    'sshPassword'?: string;
    /**
    *  The config of the executor, it could be one of the followings:  - an Executor-level YAML file path (*.yml/yaml)  - a name of a class inherited from `jina.Executor` - a docker image (must start with `docker://`) - builtin executors, e.g. `_pass`, `_logforward`, `_merge`  - the string literal of a YAML config (must start with `!`) - the string literal of a JSON config - the string literal of a YAML driver config (must start with `- !!`)  When use it under Python, one can use the following values additionally: - a Python dict that represents the config - a text file stream has `.read()` interface 
    */
    'uses'?: string;
    /**
    *  The customized python modules need to be imported before loading the executor  Note, when importing multiple files and there is a dependency between them, then one has to write the dependencies in  reverse order. That is, if `__init__.py` depends on `A.py`, which again depends on `B.py`, then you need to write:   --py-modules __init__.py --py-modules B.py --py-modules A.py  
    */
    'pyModules'?: Array<string>;
    /**
    * The port for input data, default a random port between [49152, 65535]
    */
    'portIn'?: number;
    /**
    * The port for output data, default a random port between [49152, 65535]
    */
    'portOut'?: number;
    /**
    * The host address for input, by default it is 0.0.0.0
    */
    'hostIn'?: string;
    /**
    * The host address for output, by default it is 0.0.0.0
    */
    'hostOut'?: string;
    /**
    * The socket type for input port
    */
    'socketIn'?: string;
    /**
    * The socket type for output port
    */
    'socketOut'?: string;
    /**
    * Serialize the model in the pod every n seconds if model changes. -1 means --read-only. 
    */
    'dumpInterval'?: number;
    /**
    * If set, do not allow the pod to modify the model, dump_interval will be ignored
    */
    'readOnly'?: boolean;
    /**
    * The memory high watermark of this pod in Gigabytes, pod will restart when this is reached. -1 means no restriction
    */
    'memoryHwm'?: number;
    /**
    *  The skip strategy on exceptions.  - IGNORE: Ignore it, keep running all Drivers & Executors logics in the sequel flow - SKIP_EXECUTOR: Skip all Executors in the sequel, but drivers are still called - SKIP_HANDLE: Skip all Drivers & Executors in the sequel, only `pre_hook` and `post_hook` are called - THROW_EARLY: Immediately throw the exception, the sequel flow will not be running at all                       Note, `IGNORE`, `SKIP_EXECUTOR` and `SKIP_HANDLE` do not guarantee the success execution in the sequel flow. If something  is wrong in the upstream, it is hard to carry this exception and moving forward without any side-effect. 
    */
    'onErrorStrategy'?: string;
    /**
    * the number of messages expected from upstream, 0 and 1 means single part
    */
    'numPart'?: number;
    /**
    *  The config runs inside the Docker container.   Syntax and function are the same as `--uses`. This is designed when `--uses=\"docker://...\"` this config is passed to  the Docker container. 
    */
    'usesInternal'?: string;
    /**
    * The entrypoint command overrides the ENTRYPOINT in Docker image. when not set then the Docker image ENTRYPOINT takes effective.
    */
    'entrypoint'?: string;
    /**
    * Pull the latest image before running
    */
    'pullLatest'?: boolean;
    /**
    *  The path on the host to be mounted inside the container.   Note,  - If separated by `:`, then the first part will be considered as the local host path and the second part is the path in the container system.  - If no split provided, then the basename of that directory will be mounted into container\'s root path, e.g. `--volumes=\"/user/test/my-workspace\"` will be mounted into `/my-workspace` inside the container.  - All volumes are mounted with read-write mode. 
    */
    'volumes'?: Array<string>;
    /**
    * The host address of the runtime, by default it is 0.0.0.0.
    */
    'host'?: string;
    /**
    * The port of the host exposed to the public
    */
    'portExpose'?: number;
    /**
    * Do not display the streaming of remote logs on local console
    */
    'silentRemoteLogs'?: boolean;
    /**
    *  The files on the host to be uploaded to the remote workspace. This can be useful when your Pod has more file dependencies beyond a single YAML file, e.g. Python files, data files.  Note, - currently only flatten structure is supported, which means if you upload `[./foo/a.py, ./foo/b.pp, ./bar/c.yml]`, then they will be put under the _same_ workspace on the remote, losing all hierarchies. - by default, `--uses` YAML file is always uploaded. - uploaded files are by default isolated across the runs. To ensure files are submitted to the same workspace across different runs, use `--workspace-id` to specify the workspace. 
    */
    'uploadFiles'?: Array<string>;
    /**
    * the UUID for identifying the workspace. When not given a random id will be assigned.Multiple Pea/Pod/Flow will work under the same workspace if they share the same `workspace-id`.
    */
    'workspaceId'?: string;
    /**
    * The Pea attempts to terminate all of its Runtime child processes/threads on existing. setting it to true basically tell the Pea do not wait on the Runtime when closing
    */
    'daemon'?: boolean;
    /**
    * The parallel backend of the runtime inside the Pea
    */
    'runtimeBackend'?: string;
    /**
    * The runtime class to run inside the Pea
    */
    'runtimeCls'?: string;
    /**
    * The timeout in milliseconds of a Pea waits for the runtime to be ready, -1 for waiting forever
    */
    'timeoutReady'?: number;
    /**
    * If set, expose the public IP address to remote when necessary, by default it exposesprivate IP address, which only allows accessing under the same network/subnet. Important to set this to true when the Pea will receive input connections from remote Peas
    */
    'exposePublic'?: boolean;
    /**
    * defines the suffix for the workspace path of the pea`
    */
    'peaId'?: number;
    /**
    * The role of this Pea in a Pod
    */
    'peaRole'?: string;

    static discriminator: string | undefined = undefined;

    static attributeTypeMap: Array<{name: string, baseName: string, type: string}> = [
        {
            "name": "name",
            "baseName": "name",
            "type": "string"
        },
        {
            "name": "logConfig",
            "baseName": "log_config",
            "type": "string"
        },
        {
            "name": "hideExcInfo",
            "baseName": "hide_exc_info",
            "type": "boolean"
        },
        {
            "name": "portCtrl",
            "baseName": "port_ctrl",
            "type": "number"
        },
        {
            "name": "ctrlWithIpc",
            "baseName": "ctrl_with_ipc",
            "type": "boolean"
        },
        {
            "name": "timeoutCtrl",
            "baseName": "timeout_ctrl",
            "type": "number"
        },
        {
            "name": "sshServer",
            "baseName": "ssh_server",
            "type": "string"
        },
        {
            "name": "sshKeyfile",
            "baseName": "ssh_keyfile",
            "type": "string"
        },
        {
            "name": "sshPassword",
            "baseName": "ssh_password",
            "type": "string"
        },
        {
            "name": "uses",
            "baseName": "uses",
            "type": "string"
        },
        {
            "name": "pyModules",
            "baseName": "py_modules",
            "type": "Array<string>"
        },
        {
            "name": "portIn",
            "baseName": "port_in",
            "type": "number"
        },
        {
            "name": "portOut",
            "baseName": "port_out",
            "type": "number"
        },
        {
            "name": "hostIn",
            "baseName": "host_in",
            "type": "string"
        },
        {
            "name": "hostOut",
            "baseName": "host_out",
            "type": "string"
        },
        {
            "name": "socketIn",
            "baseName": "socket_in",
            "type": "string"
        },
        {
            "name": "socketOut",
            "baseName": "socket_out",
            "type": "string"
        },
        {
            "name": "dumpInterval",
            "baseName": "dump_interval",
            "type": "number"
        },
        {
            "name": "readOnly",
            "baseName": "read_only",
            "type": "boolean"
        },
        {
            "name": "memoryHwm",
            "baseName": "memory_hwm",
            "type": "number"
        },
        {
            "name": "onErrorStrategy",
            "baseName": "on_error_strategy",
            "type": "string"
        },
        {
            "name": "numPart",
            "baseName": "num_part",
            "type": "number"
        },
        {
            "name": "usesInternal",
            "baseName": "uses_internal",
            "type": "string"
        },
        {
            "name": "entrypoint",
            "baseName": "entrypoint",
            "type": "string"
        },
        {
            "name": "pullLatest",
            "baseName": "pull_latest",
            "type": "boolean"
        },
        {
            "name": "volumes",
            "baseName": "volumes",
            "type": "Array<string>"
        },
        {
            "name": "host",
            "baseName": "host",
            "type": "string"
        },
        {
            "name": "portExpose",
            "baseName": "port_expose",
            "type": "number"
        },
        {
            "name": "silentRemoteLogs",
            "baseName": "silent_remote_logs",
            "type": "boolean"
        },
        {
            "name": "uploadFiles",
            "baseName": "upload_files",
            "type": "Array<string>"
        },
        {
            "name": "workspaceId",
            "baseName": "workspace_id",
            "type": "string"
        },
        {
            "name": "daemon",
            "baseName": "daemon",
            "type": "boolean"
        },
        {
            "name": "runtimeBackend",
            "baseName": "runtime_backend",
            "type": "string"
        },
        {
            "name": "runtimeCls",
            "baseName": "runtime_cls",
            "type": "string"
        },
        {
            "name": "timeoutReady",
            "baseName": "timeout_ready",
            "type": "number"
        },
        {
            "name": "exposePublic",
            "baseName": "expose_public",
            "type": "boolean"
        },
        {
            "name": "peaId",
            "baseName": "pea_id",
            "type": "number"
        },
        {
            "name": "peaRole",
            "baseName": "pea_role",
            "type": "string"
        }    ];

    static getAttributeTypeMap() {
        return PeaModel.attributeTypeMap;
    }
}

